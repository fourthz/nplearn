<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Goodness of Fit • nplearn</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/all.min.css" integrity="sha256-nAmazAk6vS34Xqo0BSrTb+abbtFlgsFK7NKSi6o7Y78=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/v4-shims.min.css" integrity="sha256-6qHlizsOWFskGlwVOKuns+D1nB6ssZrHQrNj1wGplHc=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/headroom.min.js" integrity="sha256-DJFC1kqIhelURkuza0AvYal5RxMtpzLjFhsnVIeuk+U=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Goodness of Fit">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">nplearn</a>
        <span class="version label label-danger" data-toggle="tooltip" data-placement="bottom" title="Unreleased version">0.0.0.9019</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/Bernoulli-Events.html">Bernoulli Events</a>
    </li>
    <li>
      <a href="../articles/binomdist.html">The Binomial Distribution</a>
    </li>
    <li>
      <a href="../articles/FisherIrwin.html">The Fisher-Irwin Test</a>
    </li>
    <li>
      <a href="../articles/gof.html">Goodness of Fit</a>
    </li>
    <li>
      <a href="../articles/ksamp.html">K-Sample Methods for Quantitative Data</a>
    </li>
    <li>
      <a href="../articles/lsprop.html">Large-Sample Proportion Inference</a>
    </li>
    <li>
      <a href="../articles/OnePropExact.html">Exact Inference for a Single Proportion</a>
    </li>
    <li>
      <a href="../articles/ProdBinom.html">The Product Binomial</a>
    </li>
    <li>
      <a href="../articles/randomization.html">Randomization Tests</a>
    </li>
    <li>
      <a href="../articles/releffic.html">Relative Efficiency</a>
    </li>
    <li>
      <a href="../articles/ReplaceScores.html">Replacement Scores</a>
    </li>
    <li>
      <a href="../articles/signtest.html">The Sign Test</a>
    </li>
    <li>
      <a href="../articles/twosamp.html">Two Sample Procedures</a>
    </li>
    <li>
      <a href="../articles/Workflow-Sample.html">Workflow Sample</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Goodness of Fit</h1>
            
      
      
      <div class="hidden name"><code>gof.Rmd</code></div>

    </div>

    
    
<p>We use the binomial distribution when our measure consists of only two possible outcomes, such as “pass” and “fail”. Yet when we have a categorical response variable, we might still have more than two potential outcomes. Examples of this would be responses on a Likert scale, such as “Strongly Disagree”, “Disagree”, “Agree”, and “Strongly Agree”, or the classification of a person’s political preference, such as “Democrat”, “Republican”, and “independent”. This vignette is about inference with a categorical response variable for which there are at least two potential responses.</p>
<div id="required-packages" class="section level3">
<h3 class="hasAnchor">
<a href="#required-packages" class="anchor"></a>Required packages</h3>
<p>The packages required for this vignette are nplearn and EMT.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" title="1"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(nplearn)</a>
<a class="sourceLine" id="cb1-2" title="2"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(EMT)</a></code></pre></div>
</div>
<div id="the-multinomial-coefficient" class="section level3">
<h3 class="hasAnchor">
<a href="#the-multinomial-coefficient" class="anchor"></a>The multinomial coefficient</h3>
<p>Consider a hypothetical scenario in which an instructor teaches five students how to take notes about a lecture one of three ways: linear notes, outline notes, or matrix notes. The students are provided opportunities to take and use each of these note types, after which each student is asked to identify their preferred notetaking type. The question of interest is whether one type of notetaking is preferred over the other types.</p>
<p>Consider <em>n</em> objects grouped into <em>k</em> mutually exclusive and exhaustive subsets. The term <em>mutually exclusive</em> means that an object can be put in one and only one subset. The term <em>exhaustive</em> means that we are considering all subsets of interest so that the sum of the number of objects in all subsets is equal to the total number of objects. The multinomial coefficient can be used to calculate the number of unique permutations when subsets consist of like objects. Here’s the formula for the multinomial coefficient.</p>
<p><span class="math inline">\(\binom{n}{x_1 \;x_2 \;... \;x_k}\)</span></p>
<p>In this equation, each <em>x</em> represents the number of objects in a particular response category. For example, suppose we want to know how many permutations of our seven student responses will involve 1 who prefers linear notes, 1 who prefers outline notes, and 3 who prefer matrix notes. Here’s the calculation.</p>
<p><span class="math inline">\(\frac{5!}{1!1!3!}\)</span></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" title="1"><span class="kw"><a href="https://rdrr.io/r/base/Special.html">factorial</a></span>(<span class="dv">5</span>)<span class="op">/</span>(<span class="kw"><a href="https://rdrr.io/r/base/Special.html">factorial</a></span>(<span class="dv">1</span>)<span class="op">*</span><span class="kw"><a href="https://rdrr.io/r/base/Special.html">factorial</a></span>(<span class="dv">1</span>)<span class="op">*</span><span class="kw"><a href="https://rdrr.io/r/base/Special.html">factorial</a></span>(<span class="dv">3</span>))</a>
<a class="sourceLine" id="cb2-2" title="2"><span class="co">#&gt; [1] 20</span></a></code></pre></div>
<p>There are 20 different permutation of choices for these five students. You likely noticed by now that the multinomial coefficient is simply an extension of the binomial coefficient. Indeed, when we only have two possible response categories, the formula becomes the formula for the binomial coefficient.</p>
<p><span class="math inline">\(\binom{n}{x_1 \;x_2} = \frac{n!}{x!(n-x)!}\)</span></p>
</div>
<div id="the-multinomial-distribution" class="section level3">
<h3 class="hasAnchor">
<a href="#the-multinomial-distribution" class="anchor"></a>The multinomial distribution</h3>
<p>Knowing that this is an extension of the binomial coefficient should lead you to surmise that the multinomial distribution is an extension of the binomial distribution, and indeed that is the case. A multinomial event is an event with <em>k</em> possible outcomes that are mutually exclusive. The probability of one ordering of multinomial events is the product of the individual event probabilities. If there are <em>x</em> units in a category, then we can write the formula for the probability of one ordering of multinomial events like this.</p>
<p><span class="math inline">\(\left( \pi^{x_1}_1 \right)\left( \pi^{x_2}_2 \right)...\left( \pi^{x_k}_k \right)\)</span></p>
<p>Suppose in our notes example we hypothesize that each type of note is equally liked in the population of notetakers. Then the probability of specific named students responding such that one prefers linear, one prefers outline, and three prefer matrix would be calculated like this.</p>
<p><span class="math inline">\(\left( \frac{1}{3} \right)\left( \frac{1}{3} \right)\left( \frac{1}{3} \right)^3\)</span></p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" title="1">(<span class="dv">1</span><span class="op">/</span><span class="dv">3</span>)<span class="op">*</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">3</span>)<span class="op">*</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">3</span>)<span class="op">^</span><span class="dv">3</span></a>
<a class="sourceLine" id="cb3-2" title="2"><span class="co">#&gt; [1] 0.004115226</span></a></code></pre></div>
<p>Of course it doesn’t matter to our study which particular student is in each of the three conditions, as long as we know that the pattern is 1, 1, and 3. We saw above that this pattern can occur 20 different ways with five students, so our total probability of obtaining this pattern is the probability of one particular ordering, multipled by 20.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" title="1"><span class="dv">20</span><span class="op">*</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">3</span>)<span class="op">*</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">3</span>)<span class="op">*</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">3</span>)<span class="op">^</span><span class="dv">3</span></a>
<a class="sourceLine" id="cb4-2" title="2"><span class="co">#&gt; [1] 0.08230453</span></a></code></pre></div>
<p>To construct the entire multinomial distribution, we have to consider all possible outcomes. Thus, we have to vary the number in each group from 0 to the total number of units, but do so in such a way that the total in all groups is equal to the total number of units. For example, with our five students we could have patterns like these.</p>
<p><span class="math inline">\(5 \;0 \;0\)</span></p>
<p><span class="math inline">\(4 \;1 \;0\)</span></p>
<p><span class="math inline">\(2 \;2 \;1\)</span></p>
<p>But we could not have the following patterns, even though we are keeping the number in each notetaking type no more than 5.</p>
<p><span class="math inline">\(5 \;4 \;1\)</span></p>
<p><span class="math inline">\(3 \;3 \;3\)</span></p>
<p>These are not possible because the total number must sum to 5. Forunately, our <em>nplearn</em> package has a function that will produce the entire multinomial distribution. We have to send it our observation as well as our hypothesized probability of preference for each note taking type.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" title="1">observed &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">3</span>)</a>
<a class="sourceLine" id="cb5-2" title="2">probs &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="dv">1</span><span class="op">/</span><span class="dv">3</span>, <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>, <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>)</a>
<a class="sourceLine" id="cb5-3" title="3"><span class="kw"><a href="../reference/mult_dist.html">mult_dist</a></span>(observed, probs)</a>
<a class="sourceLine" id="cb5-4" title="4"><span class="co">#&gt;    V1 V2 V3        prob</span></a>
<a class="sourceLine" id="cb5-5" title="5"><span class="co">#&gt; 1   5  0  0 0.004115226</span></a>
<a class="sourceLine" id="cb5-6" title="6"><span class="co">#&gt; 2   4  1  0 0.020576132</span></a>
<a class="sourceLine" id="cb5-7" title="7"><span class="co">#&gt; 3   3  2  0 0.041152263</span></a>
<a class="sourceLine" id="cb5-8" title="8"><span class="co">#&gt; 4   2  3  0 0.041152263</span></a>
<a class="sourceLine" id="cb5-9" title="9"><span class="co">#&gt; 5   1  4  0 0.020576132</span></a>
<a class="sourceLine" id="cb5-10" title="10"><span class="co">#&gt; 6   0  5  0 0.004115226</span></a>
<a class="sourceLine" id="cb5-11" title="11"><span class="co">#&gt; 7   4  0  1 0.020576132</span></a>
<a class="sourceLine" id="cb5-12" title="12"><span class="co">#&gt; 8   3  1  1 0.082304527</span></a>
<a class="sourceLine" id="cb5-13" title="13"><span class="co">#&gt; 9   2  2  1 0.123456790</span></a>
<a class="sourceLine" id="cb5-14" title="14"><span class="co">#&gt; 10  1  3  1 0.082304527</span></a>
<a class="sourceLine" id="cb5-15" title="15"><span class="co">#&gt; 11  0  4  1 0.020576132</span></a>
<a class="sourceLine" id="cb5-16" title="16"><span class="co">#&gt; 12  3  0  2 0.041152263</span></a>
<a class="sourceLine" id="cb5-17" title="17"><span class="co">#&gt; 13  2  1  2 0.123456790</span></a>
<a class="sourceLine" id="cb5-18" title="18"><span class="co">#&gt; 14  1  2  2 0.123456790</span></a>
<a class="sourceLine" id="cb5-19" title="19"><span class="co">#&gt; 15  0  3  2 0.041152263</span></a>
<a class="sourceLine" id="cb5-20" title="20"><span class="co">#&gt; 16  2  0  3 0.041152263</span></a>
<a class="sourceLine" id="cb5-21" title="21"><span class="co">#&gt; 17  1  1  3 0.082304527</span></a>
<a class="sourceLine" id="cb5-22" title="22"><span class="co">#&gt; 18  0  2  3 0.041152263</span></a>
<a class="sourceLine" id="cb5-23" title="23"><span class="co">#&gt; 19  1  0  4 0.020576132</span></a>
<a class="sourceLine" id="cb5-24" title="24"><span class="co">#&gt; 20  0  1  4 0.020576132</span></a>
<a class="sourceLine" id="cb5-25" title="25"><span class="co">#&gt; 21  0  0  5 0.004115226</span></a></code></pre></div>
<p>If we sum these probabilities, we had better get unity!</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" title="1">our.dist &lt;-<span class="st"> </span><span class="kw"><a href="../reference/mult_dist.html">mult_dist</a></span>(observed, probs)</a>
<a class="sourceLine" id="cb6-2" title="2"><span class="kw"><a href="https://rdrr.io/r/base/sum.html">sum</a></span>(our.dist<span class="op">$</span>prob)</a>
<a class="sourceLine" id="cb6-3" title="3"><span class="co">#&gt; [1] 1</span></a></code></pre></div>
</div>
<div id="the-multinomial-test" class="section level3">
<h3 class="hasAnchor">
<a href="#the-multinomial-test" class="anchor"></a>The multinomial test</h3>
<p>A reasonable null hypothesis in our study of notetaking preference would be this.</p>
<p><span class="math inline">\(H_0: \pi_1 = \frac{1}{3} \;\pi_2 = \frac{1}{3} \;\pi_3 = \frac{1}{3}\)</span></p>
<p>That is, there is an equal probability of a particular notetaking type being named as the preferred type. The alternative hypothesis here is that these proportions are not all the same, because of course we are speculating that one type may be preferred.</p>
<p>If you look at the multinomial distribution, it is clear that with five students we can’t actually observe 1/3 preferring each type. The numbers just don’t work out for that possibility. We can get close, for example, 1, 1, and 2 would be close. We want to reject the null hypothesis when our observations are most inconsistent with the null hypothesis. When is that? It’s not obvious, for example, whether an observation of 2, 3, 0 or an observation of 4, 1, 0 would be considered more inconsistent with the null hypothesis of preference equality.</p>
<p>To solve this dilemma, we can resurrect a statistic you likely learned about in an earlier statistics course: <span class="math inline">\(\chi^2\)</span>. Under the null hypothesis, we can calculate the expected number of preferences for that notetaking type.</p>
<p><span class="math inline">\(E(X_k) = n*P(X_k|H_0)\)</span></p>
<p>For example, if the null hypothesis is true, here’s how many students we expect to prefer outline notes.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" title="1"><span class="dv">5</span> <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span><span class="dv">3</span>)</a>
<a class="sourceLine" id="cb7-2" title="2"><span class="co">#&gt; [1] 1.666667</span></a></code></pre></div>
<p>There is no way to observe that many students preferring outline notes, but it doesn’t matter. What we are working on is obtaining an index of incompatibility with the null hypothesis. Such an index does not need to be an integer, even though students come in integer intervals.</p>
<p>For any given response, we can calculate an index of how far our response is from the expected value when the null hypothesis is true.</p>
<p><span class="math inline">\(\chi^2_k = \frac{\left[ X_k - E(X_k) \right]^2}{E(X_k)}\)</span></p>
<p>To obtain an “incompatibility index” (i.e., an index with higher values for observations that are more incompatible with the null hypothesis), we simply sum these values across all responses.</p>
<p><span class="math inline">\(\chi^2 = \sum \chi^2_k\)</span></p>
<p>This is often referred to as a <em>goodness of fit statistic</em>. This term is a bit misleading, because it is really a measure of <strong>lack</strong> of goodness of fit. The higher the value of the goodness of fit statistic, the more our oberved values are incompatible with the null hypothesis. As always, we conduct a hypothesis test by looking at the distribution of the goodness of fit statistic, along with the probability of obtaining the values of the statistic when the null hypothesis is true, and we first reject those values that are most incompatible with the null hypothesis.</p>
<p>The mult_dist function has an option for us to include the <span class="math inline">\(\chi^2\)</span> statistic in our distribution results and sort the distribution on the basis of this statistic.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" title="1"><span class="kw"><a href="../reference/mult_dist.html">mult_dist</a></span>(observed, probs, <span class="dt">chi2.sort =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb8-2" title="2"><span class="co">#&gt;    V1 V2 V3        prob  cumul.prob   V6</span></a>
<a class="sourceLine" id="cb8-3" title="3"><span class="co">#&gt; 1   5  0  0 0.004115226 0.004115226 10.0</span></a>
<a class="sourceLine" id="cb8-4" title="4"><span class="co">#&gt; 2   0  5  0 0.004115226 0.008230453 10.0</span></a>
<a class="sourceLine" id="cb8-5" title="5"><span class="co">#&gt; 3   0  0  5 0.004115226 0.012345679 10.0</span></a>
<a class="sourceLine" id="cb8-6" title="6"><span class="co">#&gt; 4   4  1  0 0.020576132 0.032921811  5.2</span></a>
<a class="sourceLine" id="cb8-7" title="7"><span class="co">#&gt; 5   1  4  0 0.020576132 0.053497942  5.2</span></a>
<a class="sourceLine" id="cb8-8" title="8"><span class="co">#&gt; 6   4  0  1 0.020576132 0.074074074  5.2</span></a>
<a class="sourceLine" id="cb8-9" title="9"><span class="co">#&gt; 7   0  4  1 0.020576132 0.094650206  5.2</span></a>
<a class="sourceLine" id="cb8-10" title="10"><span class="co">#&gt; 8   1  0  4 0.020576132 0.115226337  5.2</span></a>
<a class="sourceLine" id="cb8-11" title="11"><span class="co">#&gt; 9   0  1  4 0.020576132 0.135802469  5.2</span></a>
<a class="sourceLine" id="cb8-12" title="12"><span class="co">#&gt; 10  3  2  0 0.041152263 0.176954733  2.8</span></a>
<a class="sourceLine" id="cb8-13" title="13"><span class="co">#&gt; 11  2  3  0 0.041152263 0.218106996  2.8</span></a>
<a class="sourceLine" id="cb8-14" title="14"><span class="co">#&gt; 12  3  0  2 0.041152263 0.259259259  2.8</span></a>
<a class="sourceLine" id="cb8-15" title="15"><span class="co">#&gt; 13  0  3  2 0.041152263 0.300411523  2.8</span></a>
<a class="sourceLine" id="cb8-16" title="16"><span class="co">#&gt; 14  2  0  3 0.041152263 0.341563786  2.8</span></a>
<a class="sourceLine" id="cb8-17" title="17"><span class="co">#&gt; 15  0  2  3 0.041152263 0.382716049  2.8</span></a>
<a class="sourceLine" id="cb8-18" title="18"><span class="co">#&gt; 16  3  1  1 0.082304527 0.465020576  1.6</span></a>
<a class="sourceLine" id="cb8-19" title="19"><span class="co">#&gt; 17  1  3  1 0.082304527 0.547325103  1.6</span></a>
<a class="sourceLine" id="cb8-20" title="20"><span class="co">#&gt; 18  1  1  3 0.082304527 0.629629630  1.6</span></a>
<a class="sourceLine" id="cb8-21" title="21"><span class="co">#&gt; 19  2  2  1 0.123456790 0.753086420  0.4</span></a>
<a class="sourceLine" id="cb8-22" title="22"><span class="co">#&gt; 20  2  1  2 0.123456790 0.876543210  0.4</span></a>
<a class="sourceLine" id="cb8-23" title="23"><span class="co">#&gt; 21  1  2  2 0.123456790 1.000000000  0.4</span></a></code></pre></div>
<p>We now are ready to test the hypothesis of equal preference for each of the notetaking types. Given the small sample size, let’s use <span class="math inline">\(\alpha = .10\)</span>.</p>
<p>Our observed frequencies of preference were 1, 1, and 3. This corresponds to <span class="math inline">\(\chi^2 = 1.6\)</span> and the probability of 1.6, or greater, when the null hypothesis is true is 0.63. (Remember that we must include all values of 1.6 when determining the cumulative probability.)</p>
<p>We have just determined that if there is equal preference for each note taking type that there is a 63% chance of observing the preferences that we observed, or preferences even more incompatible with the null hypothesis. In goodness-of-fit terms, we can state that our observations are not incompatible with a model of equal preference.</p>
<p>One sidenote: We are dealing with unordered categories, so there is no direction to our hypothesis. Regardless of which notetaking type is preferred, as we deviate from the null hypothesis the value of <span class="math inline">\(\chi^2\)</span> grows, so we only need to perform a one-sided test in order to test for all types of incompatibility. This upper-tailed test is reflected in our statistic which is based on squared values, thus eliminating the chance for a lower tail in our distribution.</p>
<p>As you might suspect from your association with R, someone has created a function that makes it unnecessary to create the entire multinomial distribution. This is in the “EMT” package. The name of the package comes from “exact multinomial test,” which is exactly (bad pun!) what we are doing here.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" title="1"><span class="kw">multinomial.test</span>(observed, probs, <span class="dt">useChisq =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb9-2" title="2"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb9-3" title="3"><span class="co">#&gt;  Exact Multinomial Test, distance measure: chisquare</span></a>
<a class="sourceLine" id="cb9-4" title="4"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb9-5" title="5"><span class="co">#&gt;     Events    chi2Obs    p.value</span></a>
<a class="sourceLine" id="cb9-6" title="6"><span class="co">#&gt;         21        1.6     0.6296</span></a></code></pre></div>
<p>Imagine the same notetaking study, but this time with a larger sample size. Suppose that out of 100 students, 7 prefer linear notes, 21 prefer outline notes, and 72 prefer matrix notes. Let’s see what we get.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" title="1">observed &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="dv">7</span>, <span class="dv">21</span>, <span class="dv">72</span>)</a>
<a class="sourceLine" id="cb10-2" title="2"><span class="kw">multinomial.test</span>(observed, probs, <span class="dt">useChisq =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb10-3" title="3"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb10-4" title="4"><span class="co">#&gt;  Exact Multinomial Test, distance measure: chisquare</span></a>
<a class="sourceLine" id="cb10-5" title="5"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb10-6" title="6"><span class="co">#&gt;     Events    chi2Obs    p.value</span></a>
<a class="sourceLine" id="cb10-7" title="7"><span class="co">#&gt;       5151      70.22          0</span></a></code></pre></div>
<p>The <em>p</em> value is not really 0, but it is so small that 0 provides a good estimate. We have sufficient evidence to declare preferences in the population of notetaking users who are trained in all three methods. Our best guess here is that matrix notetaking is the preferred method.</p>
<p>If we want to see the entire output of this rather large distribution, we can do so, but we probably don’t want to print it to the screen. Let’s save the distribution and put it in a csv file.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" title="1">big.dist &lt;-<span class="st"> </span><span class="kw"><a href="../reference/mult_dist.html">mult_dist</a></span>(observed, probs, <span class="dt">chi2.sort =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb11-2" title="2"><span class="kw"><a href="https://rdrr.io/r/utils/write.table.html">write.csv</a></span>(big.dist, <span class="dt">file =</span> <span class="st">"myoutput.csv"</span>)</a></code></pre></div>
<p>You’ll find our observation on row 1320. The reason that the exact multinomial test function gave us a 0 is because the actual value is 0.00000000000000193, so 0 seems close enough.</p>
<p>One other item of interest while we are looking at our file. You’ll see that the largest value of <span class="math inline">\(\chi^2\)</span> is 200. It turns out that the maximum value that we can observe for <span class="math inline">\(\chi^2\)</span> is given by this formula.</p>
<p><span class="math inline">\(n*(k-1)\)</span></p>
<p>We have <em>n</em> = 100 and <em>k</em> = 3, so the value of 200 is what we should have expected.</p>
<p>Let me show you one more item of interest with the multinomial test function. I’m going to change the observed pattern to make it a bit more compatiable with the null hypothesis. I’m doing this so that we can look at <em>p</em> values that are not so close to 0.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" title="1">observed &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="dv">22</span>, <span class="dv">37</span>, <span class="dv">41</span>)</a>
<a class="sourceLine" id="cb12-2" title="2"><span class="kw">multinomial.test</span>(observed, probs, <span class="dt">useChisq =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb12-3" title="3"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb12-4" title="4"><span class="co">#&gt;  Exact Multinomial Test, distance measure: chisquare</span></a>
<a class="sourceLine" id="cb12-5" title="5"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb12-6" title="6"><span class="co">#&gt;     Events    chi2Obs    p.value</span></a>
<a class="sourceLine" id="cb12-7" title="7"><span class="co">#&gt;       5151       6.02     0.0532</span></a>
<a class="sourceLine" id="cb12-8" title="8"><span class="kw">multinomial.test</span>(observed, probs)</a>
<a class="sourceLine" id="cb12-9" title="9"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb12-10" title="10"><span class="co">#&gt;  Exact Multinomial Test, distance measure: p</span></a>
<a class="sourceLine" id="cb12-11" title="11"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb12-12" title="12"><span class="co">#&gt;     Events    pObs    p.value</span></a>
<a class="sourceLine" id="cb12-13" title="13"><span class="co">#&gt;       5151   3e-04     0.0409</span></a></code></pre></div>
<p>Notice the two different <em>p</em> values. They are not much different, but if we are using a 95% level of confidence, we would reject the null hypothesis with one of these values, but not with the other. Which one is correct? The first one. Notice in the two function calls that I set the third parameter (useChisq) to “true”. The default is “false”. What is the function doing if this parameter is false? It is sorting based on probabilities, rather than based on the chi-square statistic. Why? I have no idea, but what I can tell you is that many researchers (even some statisticians!) have the idea that we should put the lowest probabilities in our rejection region first. What we should put in our rejection region first are the observations that are most inconsistent with the null hypothesis, and these are encapsulated with the chi-square statistic. It turns out that most of the time the largest values of chi square are associated with the smallest probabilities, yet as we move to smaller and smaller values of chi-square, this may not always be the case. When it is not, our rule is to use values that align with incompatibility with the null hypothesis rather than the probability. The author of the function is aware of this issue, or he wouldn’t have put in a “useChisq” parameter. In my view, at the very least, he should have made “true” the default, rather than “false.” At least we know to set this to “true” each time we use the function.</p>
</div>
<div id="large-sample-approximations-for-the-multinomial-distribution" class="section level3">
<h3 class="hasAnchor">
<a href="#large-sample-approximations-for-the-multinomial-distribution" class="anchor"></a>Large-sample approximations for the multinomial distribution</h3>
<p>We have already seen that we can do an exact test with a sample size as large as 100. Let’s look at a study with an even bigger sample. A district manager tracked sales in three bookstores. Bookstore A and B are the same size, but Bookstore C is twice as big. The manager therefore believed that Bookstore C should be selling twice as many books as Bookstores A and B. Here are the data for one month.</p>
<p>Bookstore A: 5,325 books</p>
<p>Bookstore B: 6,202 books</p>
<p>Bookstore C: 9,849 books</p>
<p>Let’s try this. Note the null hypothesized proportions of total sales. Put these in and then go ahead and run the multinomial test.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" title="1">observed &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="dv">5325</span>, <span class="dv">6202</span>, <span class="dv">9849</span>)</a>
<a class="sourceLine" id="cb13-2" title="2">probs &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">0.25</span>, <span class="fl">0.25</span>, <span class="fl">0.50</span>)</a></code></pre></div>
<p>I’m not sure if this would work or not if we waited long enough, but if you’re like me, you gave up. What can we do? We have two good options. First, we can use a Monte Carlo method.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" title="1"><span class="kw">multinomial.test</span>(observed,</a>
<a class="sourceLine" id="cb14-2" title="2">                 probs,</a>
<a class="sourceLine" id="cb14-3" title="3">                 <span class="dt">useChisq =</span> <span class="ot">TRUE</span>,</a>
<a class="sourceLine" id="cb14-4" title="4">                 <span class="dt">MonteCarlo =</span> <span class="ot">TRUE</span>,</a>
<a class="sourceLine" id="cb14-5" title="5">                 <span class="dt">ntrial =</span> <span class="dv">100000</span>)</a>
<a class="sourceLine" id="cb14-6" title="6"><span class="co">#&gt;  </span></a>
<a class="sourceLine" id="cb14-7" title="7"><span class="co">#&gt;  </span><span class="al">WARNING</span><span class="co">: Number of simulated withdrawels is lower than the number of possible outcomes. </span></a>
<a class="sourceLine" id="cb14-8" title="8"><span class="co">#&gt;                 This might yield unreliable results!</span></a>
<a class="sourceLine" id="cb14-9" title="9"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb14-10" title="10"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb14-11" title="11"><span class="co">#&gt;  Monte Carlo Multinomial Test, distance measure: chisquare</span></a>
<a class="sourceLine" id="cb14-12" title="12"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb14-13" title="13"><span class="co">#&gt;     Events    chi2Obs    p.value</span></a>
<a class="sourceLine" id="cb14-14" title="14"><span class="co">#&gt;  228498753   203.6837          0</span></a></code></pre></div>
<p>We can reject the null hypothesis. The bookstores are not all matching with our expectations. Look at the proportions.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" title="1">observed<span class="op">/</span><span class="kw"><a href="https://rdrr.io/r/base/sum.html">sum</a></span>(observed)</a>
<a class="sourceLine" id="cb15-2" title="2"><span class="co">#&gt; [1] 0.2491112 0.2901385 0.4607504</span></a></code></pre></div>
<p>Bookstore A is right on target. Bookstore B is overperforming and Bookstore C is underperforming. Before we start firing employees, consider that <em>p</em> values are a function of both effect size and sample size. The effect size here is not very large, but the <em>p</em> value is very small because the sample size is very large. The combination of a large sample size and small effect size led to a small p value.</p>
<p>We know that a Monte Carlo study is one that involves simulation, so what did our Monte Carlo parameter do for us here. It simulated drawing multiple samples (100,000, in fact, because that is what the “ntrial” parameter tells us) from the null-hypothesized distribution. Each time, it calculated chi square and determined if that value of chi square equaled or exceeded our observed value of 204. The empirical <em>p</em> value is the number of times, out of 100,000, that it did equal or exceed 204. Pretty nifty, eh? Monte Carlo can be used to create empirical <em>p</em> values in situations where there are just far too many possible permutations to do in a reasonable amount of time. Thinking about this should lead you to consider new approaches to methods such as the Fisher-Pitman test.</p>
<p>The second option when we have a large sample size is to utilize an intriguing property of the <span class="math inline">\(\chi^2\)</span> statistic. As the sample size increases, the distribution of this statistic approaches that of a chi-square distribution with k-1 degrees of freedom. In this study we have three bookstores, so we will use 2 degrees of freedom. Note that observed chi-square value of 203.6837. We can use the “pchisq” function to obtain our <em>p</em> value.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" title="1"><span class="kw"><a href="https://rdrr.io/r/stats/Chisquare.html">pchisq</a></span>(<span class="fl">203.6837</span>, <span class="dt">df =</span> <span class="dv">2</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb16-2" title="2"><span class="co">#&gt; [1] 5.897209e-45</span></a></code></pre></div>
<p>That’s pretty close to 0!</p>
<p>Just for grins, let’s go back to my earlier example when I obtained <em>p</em> values not so close to 0 with <em>n</em> = 100. Let’s now compare the exact method, the Monte Carlo method, and the large-sample chi-square distribution method.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" title="1">observed &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="dv">22</span>, <span class="dv">37</span>, <span class="dv">41</span>)</a>
<a class="sourceLine" id="cb17-2" title="2">probs &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="dv">1</span><span class="op">/</span><span class="dv">3</span>, <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>, <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>)</a>
<a class="sourceLine" id="cb17-3" title="3"></a>
<a class="sourceLine" id="cb17-4" title="4"><span class="kw">multinomial.test</span>(observed, probs, <span class="dt">useChisq =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb17-5" title="5"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb17-6" title="6"><span class="co">#&gt;  Exact Multinomial Test, distance measure: chisquare</span></a>
<a class="sourceLine" id="cb17-7" title="7"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb17-8" title="8"><span class="co">#&gt;     Events    chi2Obs    p.value</span></a>
<a class="sourceLine" id="cb17-9" title="9"><span class="co">#&gt;       5151       6.02     0.0532</span></a>
<a class="sourceLine" id="cb17-10" title="10"></a>
<a class="sourceLine" id="cb17-11" title="11"><span class="kw">multinomial.test</span>(observed,</a>
<a class="sourceLine" id="cb17-12" title="12">                 probs,</a>
<a class="sourceLine" id="cb17-13" title="13">                 <span class="dt">useChisq =</span> <span class="ot">TRUE</span>,</a>
<a class="sourceLine" id="cb17-14" title="14">                 <span class="dt">MonteCarlo =</span> <span class="ot">TRUE</span>,</a>
<a class="sourceLine" id="cb17-15" title="15">                 <span class="dt">ntrial =</span> <span class="dv">100000</span>)</a>
<a class="sourceLine" id="cb17-16" title="16"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb17-17" title="17"><span class="co">#&gt;  Monte Carlo Multinomial Test, distance measure: chisquare</span></a>
<a class="sourceLine" id="cb17-18" title="18"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb17-19" title="19"><span class="co">#&gt;     Events    chi2Obs    p.value</span></a>
<<<<<<< HEAD
<a class="sourceLine" id="cb17-20" title="20"><span class="co">#&gt;       5151       6.02     0.0537</span></a>
=======
<a class="sourceLine" id="cb17-20" title="20"><span class="co">#&gt;       5151       6.02     0.0535</span></a>
>>>>>>> master
<a class="sourceLine" id="cb17-21" title="21"></a>
<a class="sourceLine" id="cb17-22" title="22">expected &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/sum.html">sum</a></span>(observed)<span class="op">*</span>probs</a>
<a class="sourceLine" id="cb17-23" title="23">x2 &lt;-<span class="st"> </span>(observed <span class="op">-</span><span class="st"> </span>expected)<span class="op">^</span><span class="dv">2</span><span class="op">/</span>expected</a>
<a class="sourceLine" id="cb17-24" title="24">x2 &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/sum.html">sum</a></span>(x2)</a>
<a class="sourceLine" id="cb17-25" title="25"><span class="kw"><a href="https://rdrr.io/r/stats/Chisquare.html">pchisq</a></span>(x2, <span class="dt">df =</span> <span class="dv">2</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb17-26" title="26"><span class="co">#&gt; [1] 0.04929168</span></a></code></pre></div>
<p>The results are all quite close, but the Monte Carlo results are better than those using the asymptotic distribution. Most of the world uses this latter method, but you now know that there is a better way.</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">

      </div>

</div>



      <footer><div class="copyright">
  <p>Developed by Michael Seaman.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.4.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
